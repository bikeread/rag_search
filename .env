# LLM Settings
# 可选值: huggingface, ollama
LLM_PROVIDER=ollama
LLM_MODEL=deepseek-r1:7b
LLM_TEMPERATURE=0.3
LLM_MAX_TOKENS=4096

# Ollama specific settings
OLLAMA_BASE_URL=http://localhost:11434
# 请求超时时间（秒）
OLLAMA_TIMEOUT=120

# Vector Database Settings
# 可选值: faiss, milvus
VECTOR_DB_TYPE=milvus
VECTOR_DB_PATH=data/vector_store.milvus
# 中文优化的嵌入模型
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
# Device to use for embeddings (cpu or cuda)
EMBEDDING_DEVICE=cpu

# Milvus 专用配置
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_COLLECTION=document_store
MILVUS_TIMEOUT=30
MILVUS_USE_ALIASES=false

# Document Processing Settings
DEFAULT_ENCODING=utf-8
DEFAULT_LANGUAGE=zh

# Unstructured Settings
# 文档处理策略: fast (快速) 或 accurate (精确)
UNSTRUCTURED_STRATEGY=accurate
# OCR 支持的语言，使用逗号分隔
UNSTRUCTURED_OCR_LANGUAGES=eng,chi_sim
# 是否启用 OCR
UNSTRUCTURED_ENABLE_OCR=true
# PDF OCR 阈值，低于此值的文本质量将使用 OCR
UNSTRUCTURED_PDF_OCR_THRESHOLD=0.8
# 图片处理的最小尺寸（像素）
UNSTRUCTURED_IMAGE_MIN_SIZE=100
# 高分辨率文档处理模型（可选）
UNSTRUCTURED_HI_RES_MODEL=

# API Settings
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=true

# RAG Settings
# 文档分块设置（用于文档处理和RAG）
# 中文文档，使用较大的块大小
CHUNK_SIZE=1024
# 20% 的重叠
CHUNK_OVERLAP=200
TOP_K_RESULTS=5

# Vector Search Settings
# 检索候选数量倍数
SEARCH_MULTIPLIER=3
# 相似度阈值
MIN_SIMILARITY_SCORE=0.001

# Vector Index Settings
# 是否使用IVF索引（大数据集使用true）
USE_IVF_INDEX=false
# IVF聚类中心数量
IVF_NLIST=100
# IVF探测数量
IVF_NPROBE=10

# Monitoring Settings
PROMETHEUS_PORT=9090
LOG_LEVEL=DEBUG

# Vector Processing Settings
# 向量化方法: tfidf, word2vec, bert
VECTORIZATION_METHOD=bert
# 向量维度
VECTOR_DIMENSIONS=768
# 是否对文档块进行向量化 (true/false)
ENABLE_VECTORIZATION=true

TFIDF_MAX_FEATURES=5000
TFIDF_USE_IDF=true

# Table Processing Settings
# 表格处理每个块的最大行数
TABLE_MAX_ROWS_PER_CHUNK=1
# 是否保留空单元格
TABLE_PRESERVE_EMPTY_CELLS=false
# 单元格分隔符
TABLE_CELL_SEPARATOR="|"
# 键值对分隔符
TABLE_KEY_VALUE_SEPARATOR=": "
# 表头所在行（从0开始）
TABLE_HEADER_ROW=0

# Word2Vec配置
WORD2VEC_VECTOR_SIZE=100
WORD2VEC_WINDOW=5
WORD2VEC_MIN_COUNT=1
WORD2VEC_WORKERS=4
WORD2VEC_PRETRAINED_PATH=

# BERT配置（如果未设置，将使用EMBEDDING_MODEL）
BERT_MODEL_NAME=bert-base-chinese
BERT_MAX_LENGTH=512

# BGE-M3配置（如果未设置，将使用EMBEDDING_MODEL）
BGE_MODEL_NAME=BAAI/bge-m3
BGE_MAX_LENGTH=512

# 查询增强配置
QUERY_ENHANCEMENT_ENABLED=true
QUERY_DECOMPOSITION_ENABLED=true
QUERY_EXPANSION_ENABLED=true
KEYWORD_EXTRACTION_ENABLED=true
MAX_ENHANCED_DOCS=10
